{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает\n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn (это возможно, так как мы реализуем только малую часть функциональности)\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала так же или качественнее, чем у дерева из sklearn\n",
    "5. Применить реализованное дерево решений для задачи Titanic на kaggle. Применить для той же задачи дерево решений из sklearn. Применить кросс-валидацию для подбора параметров. Сравнить с результатами предыдущих моделей. Если результат улучшился - сделать сабмит. Написать отчет о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "1                 1                              0.766127   45   \n",
       "2                 0                              0.957151   40   \n",
       "3                 0                              0.658180   38   \n",
       "4                 0                              0.233810   30   \n",
       "5                 0                              0.907239   49   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "1                                     2   0.802982         9120.0   \n",
       "2                                     0   0.121876         2600.0   \n",
       "3                                     1   0.085113         3042.0   \n",
       "4                                     0   0.036050         3300.0   \n",
       "5                                     1   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "1                               13                        0   \n",
       "2                                4                        0   \n",
       "3                                2                        1   \n",
       "4                                5                        0   \n",
       "5                                7                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "1                             6                                     0   \n",
       "2                             0                                     0   \n",
       "3                             0                                     0   \n",
       "4                             0                                     0   \n",
       "5                             1                                     0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "1                 2.0  \n",
       "2                 1.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "5                 0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./cs-training.csv', sep=',').dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self,\n",
    "                 min_samples_split=2,\n",
    "                 max_depth=None,\n",
    "                 sufficient_share=1.0,\n",
    "                 criterion='gini',\n",
    "                 max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            raise ValueError('invalid criterion name')\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            raise ValueError('invalid max_features name')\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        # 1. Мера неопределенности родительского узла\n",
    "        i_p = self.__gini_p((l_c + r_c) / (l_s + r_s))\n",
    "        # 2. Мера неопределенности левого дочернего узла\n",
    "        i_l = self.__gini_p(l_c / l_s)\n",
    "        # 3. Мера неопределенности правого дочернего узла\n",
    "        i_r = self.__gini_p(r_c / r_s)\n",
    "        return self.__impurity(i_p, i_l, i_r, l_s, r_s)\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        # 1. Мера неопределенности родительского узла\n",
    "        i_p = self.__entropy_p((l_c + r_c) / (l_s + r_s))\n",
    "        # 2. Мера неопределенности левого дочернего узла\n",
    "        i_l = self.__entropy_p(l_c / l_s)\n",
    "        # 3. Мера неопределенности правого дочернего узла\n",
    "        i_r = self.__entropy_p(r_c / r_s)\n",
    "        return self.__impurity(i_p, i_l, i_r, l_s, r_s)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        # 1. Мера неопределенности родительского узла\n",
    "        i_p = self.__misclass_p((l_c + r_c) / (l_s + r_s))\n",
    "        # 2. Мера неопределенности левого дочернего узла\n",
    "        i_l = self.__misclass_p(l_c / l_s)\n",
    "        # 3. Мера неопределенности правого дочернего узла\n",
    "        i_r = self.__misclass_p(r_c / r_s)\n",
    "        return self.__impurity(i_p, i_l, i_r, l_s, r_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        max_features = max(1, int(np.sqrt(n_feature)))\n",
    "        return feature_ids[:max_features]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        max_features = max(1, int(np.log2(n_feature)))\n",
    "        return feature_ids[:max_features]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return range(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Сортируем значения свойства по возрастанию и приводим к аналогичной последовательности целевые переменные.\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        # Количество меток класса.\n",
    "        class_number = np.unique(y).shape[0]\n",
    "\n",
    "        # Здесь, по всей видимости, мы обрезаем образцы с учетом параметра min_samples_split, для того, \n",
    "        # чтобы в середине осталось необходимое количество образцов размера min_samples_split. \n",
    "        # Хотя это немного странный подход, можно проверять min_samples_split заранее.\n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "        # Сравниваем каждый элемент с предыдущим, таким образом мы получаем информацию о том насколько неоднородная выборка,\n",
    "        # это будет иметь влияния на вычисление меры неоднородности.\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "        \n",
    "        # Если выборка однородная, то нет необходимости делать расщепление.\n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None\n",
    "        \n",
    "        # Что происходит деталях объяснить не так легко, но судя по отладочной информации, \n",
    "        # основной смысл данного участка кода - сформировать различные варианты разбиения классов, \n",
    "        # на основе которых можно вычислить различные меры неоднородности и выбрать из них наиболее оптимальную.\n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] \\\n",
    "            + np.bincount(sorted_y[:self.min_samples_split], minlength=class_number)\n",
    "\n",
    "        # Здесь создаются различные варианты разбиения классов по узлам дерева:\n",
    "        # l_class_count - варианты разбиения для левого узла\n",
    "        # r_class_count - варианты разбиения для правого узла\n",
    "        # l_sizes - общее число образцов в левом узле\n",
    "        # r_sizes - общее число образцов в правом узле\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Вычисляем возможные меры неоднородности для всех вариантов разбиения классов.\n",
    "        # Выбираем индекс наименьшей из них, как наиболее оптимальный. \n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "    \n",
    "        # По индексу лучшей неоднородности, определяем количество элементов в левом узле.\n",
    "        # Возвращаем значение лучшей меры неоднородности и среднее значение элемента выборки \n",
    "        # (сам элемент и его сосед слева), который и будет являться тем самым параметром threshold, \n",
    "        # по которому будет определяться разделение выборки на правый и левый узлы.\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        # Если узел содержит только образцы одного класса, то останавливаем расщепление.\n",
    "        if np.unique(y).shape[0] == 1:\n",
    "            self.tree[node_id] = (\n",
    "                self.LEAF_TYPE,\n",
    "                y[0],\n",
    "                0,\n",
    "                0,\n",
    "                y,\n",
    "                'Node contains only samples of one class',\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # Если доля образцов одного класса больше или равна необходимой доли для расщепления, то останавливаем расщепление.\n",
    "        most_common_y = Counter(y).most_common(1).pop()\n",
    "        if most_common_y[1] >= self.sufficient_share * y.shape[0]:\n",
    "            self.tree[node_id] = (\n",
    "                self.LEAF_TYPE,\n",
    "                most_common_y[0],\n",
    "                0,\n",
    "                0,\n",
    "                y,\n",
    "                'Samples of one class is greater than or equal sufficient_share',\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # Если достигнута максимальная глубина дерева, то останавливаем расщепление.\n",
    "        # Делаем предсказание по классу с наибольшим количеством образцов.\n",
    "        if self.max_depth == depth:\n",
    "            self.tree[node_id] = (\n",
    "                self.LEAF_TYPE,\n",
    "                most_common_y[0],\n",
    "                0,\n",
    "                0,\n",
    "                y,\n",
    "                'Maximum depth of the tree',\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # Если количество образцов меньше требуемого для разделения узла, то останавливаем расщепление.\n",
    "        # Делаем предсказание по классу с наибольшим количеством образцов.\n",
    "        if y.shape[0] < self.min_samples_split:\n",
    "            self.tree[node_id] = (\n",
    "                self.LEAF_TYPE,\n",
    "                most_common_y[0],\n",
    "                0,\n",
    "                0,\n",
    "                y,\n",
    "                'Number of samples is less than min_samples_split',\n",
    "            )\n",
    "            return\n",
    "        \n",
    "        n_samples, n_features = x.shape\n",
    "        split_data = []\n",
    "        # Ищем признак по которому будем делать разбиение (который ведет к самому большому приросту информации).\n",
    "        # Для этого необходимо вычислить для каждого признака меру неоднородности (impurity).\n",
    "        # Чем ниже неоднородность, тем выше прирост информации.\n",
    "        # Также здесь мы вычисляем порог (threshold), \n",
    "        # по которому будем определять идти в правый узел дерева или левый (т.к. дерево у нас бинарное).\n",
    "        for feature_id in self.get_feature_ids(n_features):\n",
    "            impurity, threshold = self.__find_threshold(x[:,feature_id], y)\n",
    "            if threshold is not None:\n",
    "                split_data.append((impurity, threshold, feature_id,))\n",
    "\n",
    "        # Если недостаточно данных для разбиения, например, \n",
    "        # достигнут предел минимального количества образцов, то останавливаем расщепление.\n",
    "        # Делаем предсказание по классу с наибольшим количеством образцов.\n",
    "        if not split_data:\n",
    "            self.tree[node_id] = (\n",
    "                self.LEAF_TYPE,\n",
    "                most_common_y[0],\n",
    "                0,\n",
    "                0,\n",
    "                y,\n",
    "                'Empty split data',\n",
    "            )\n",
    "            return\n",
    "\n",
    "        best_split = min(split_data, key=lambda x: x[0])\n",
    "            \n",
    "        x_left, x_right, y_left, y_right = self.__div_samples(x, y, best_split[2], best_split[1])\n",
    "\n",
    "        # Если после расщепления, какой либо узел оказался пустой, то значит, данный узел расщепить невозможно, \n",
    "        # поэтому он будет являться листом.\n",
    "        # Делаем предсказание по классу с наибольшим количеством образцов.\n",
    "        if y_left.shape[0] == 0 or y_right.shape[0] == 0:\n",
    "            self.tree[node_id] = (\n",
    "                self.LEAF_TYPE,\n",
    "                most_common_y[0],\n",
    "                0,\n",
    "                0,\n",
    "                y,\n",
    "                'After splitting one of the nodes is empty',\n",
    "            )\n",
    "            return\n",
    "        else:\n",
    "            self.tree[node_id] = (self.NON_LEAF_TYPE, best_split[2], best_split[1], best_split[0], y, None)\n",
    "            self.__fit_node(x_left, y_left, 2 * node_id + 1, depth + 1)\n",
    "            self.__fit_node(x_right, y_right, 2 * node_id + 2, depth + 1)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold, *_ = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold, *_ = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "\n",
    "    @staticmethod\n",
    "    def __gini_p(p):\n",
    "        return 1 - (p ** 2).sum(axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def __entropy_p(p):\n",
    "        return - np.nansum(p * np.log2(p), axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def __misclass_p(p):   \n",
    "        return 1 - p.max(axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def __impurity(i_p, i_l, i_r, l_s, r_s):\n",
    "        t_s = l_s + r_s\n",
    "        return i_p - (np.squeeze(np.asarray(l_s / t_s)) * i_l) - (np.squeeze(np.asarray(r_s / t_s)) * i_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_debug = df.sample(n=100)\n",
    "x_debug = df_debug.as_matrix(columns=df_debug.columns[1:])\n",
    "y_debug = df_debug.as_matrix(columns=df_debug.columns[:1])\n",
    "y_debug = y_debug.reshape(y_debug.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_clf_debug = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "my_clf_debug.fit(x_debug, y_debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree, node_id=0, depth=0, df=None, df_shift=0):\n",
    "    node = tree.get(node_id)\n",
    "    if node:\n",
    "        tab = '\\t' * depth\n",
    "        node_type, feature, threshold, impurity, y, message = node\n",
    "        y_cnt = Counter(y)\n",
    "        node_type = 'LEAF' if node_type == 1 else 'NON_LEAF'\n",
    "        if df is not None:\n",
    "            feature = df.columns[feature + df_shift]\n",
    "        if node_type == 'NON_LEAF':\n",
    "            print('\\n'.join('{}{}: {}'.format(tab, k, v) for k, v in {\n",
    "                'type': node_type,\n",
    "                'depth': depth,\n",
    "                'threshold': threshold,\n",
    "                'feature': feature,\n",
    "                'impurity': impurity,\n",
    "                'samples': '[{}]'.format(', '.join('{}:{}'.format(k, v) for k, v in y_cnt.items())),\n",
    "            }.items()))\n",
    "        else:\n",
    "            print('\\n'.join('{}{}: {}'.format(tab, k, v) for k, v in {\n",
    "                'type': node_type,\n",
    "                'depth': depth,\n",
    "                'class': threshold,\n",
    "                'samples': '[{}]'.format(', '.join('{}:{}'.format(k, v) for k, v in y_cnt.items())),\n",
    "                'message': message,\n",
    "            }.items()))\n",
    "        print('{}------------------------------'.format(tab))\n",
    "        print_tree(tree, 2 * node_id + 1, depth + 1, df)\n",
    "        print_tree(tree, 2 * node_id + 2, depth + 1, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: NON_LEAF\n",
      "depth: 0\n",
      "threshold: 5000.0\n",
      "feature: MonthlyIncome\n",
      "impurity: 5.128205128247798e-06\n",
      "samples: [0:96, 1:4]\n",
      "------------------------------\n",
      "\ttype: LEAF\n",
      "\tdepth: 1\n",
      "\tclass: 0\n",
      "\tsamples: [0:49, 1:1]\n",
      "\tmessage: After splitting one of the nodes is empty\n",
      "\t------------------------------\n",
      "\ttype: NON_LEAF\n",
      "\tdepth: 1\n",
      "\tthreshold: 1.0\n",
      "\tfeature: NumberOfTimes90DaysLate\n",
      "\timpurity: 5.8823529412374564e-06\n",
      "\tsamples: [0:47, 1:3]\n",
      "\t------------------------------\n",
      "\t\ttype: LEAF\n",
      "\t\tdepth: 2\n",
      "\t\tclass: 0\n",
      "\t\tsamples: [0:4]\n",
      "\t\tmessage: Node contains only samples of one class\n",
      "\t\t------------------------------\n",
      "\t\ttype: NON_LEAF\n",
      "\t\tdepth: 2\n",
      "\t\tthreshold: 46.5\n",
      "\t\tfeature: RevolvingUtilizationOfUnsecuredLines\n",
      "\t\timpurity: 7.8764965343453e-06\n",
      "\t\tsamples: [0:43, 1:3]\n",
      "\t\t------------------------------\n",
      "\t\t\ttype: NON_LEAF\n",
      "\t\t\tdepth: 3\n",
      "\t\t\tthreshold: 62.5\n",
      "\t\t\tfeature: RevolvingUtilizationOfUnsecuredLines\n",
      "\t\t\timpurity: 0.00016088486676724134\n",
      "\t\t\tsamples: [0:28, 1:2]\n",
      "\t\t\t------------------------------\n",
      "\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\tdepth: 4\n",
      "\t\t\t\tthreshold: 0.5\n",
      "\t\t\t\tfeature: NumberOfTime60-89DaysPastDueNotWorse\n",
      "\t\t\t\timpurity: 0.0014829461196242122\n",
      "\t\t\t\tsamples: [0:16, 1:1]\n",
      "\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\tsamples: [0:3]\n",
      "\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tthreshold: 0.596634357\n",
      "\t\t\t\t\tfeature: NumberOfTime30-59DaysPastDueNotWorse\n",
      "\t\t\t\t\timpurity: 0.0027829313543598633\n",
      "\t\t\t\t\tsamples: [0:13, 1:1]\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\tdepth: 6\n",
      "\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\tsamples: [0:3]\n",
      "\t\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\tdepth: 6\n",
      "\t\t\t\t\t\tthreshold: 0.0\n",
      "\t\t\t\t\t\tfeature: NumberOfTimes90DaysLate\n",
      "\t\t\t\t\t\timpurity: 0.009445100354191355\n",
      "\t\t\t\t\t\tsamples: [0:10, 1:1]\n",
      "\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\tdepth: 7\n",
      "\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\tsamples: [0:3]\n",
      "\t\t\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\t\tdepth: 7\n",
      "\t\t\t\t\t\t\tthreshold: 0.0\n",
      "\t\t\t\t\t\t\tfeature: age\n",
      "\t\t\t\t\t\t\timpurity: 0.0187500000000001\n",
      "\t\t\t\t\t\t\tsamples: [0:7, 1:1]\n",
      "\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\tdepth: 8\n",
      "\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\tsamples: [0:1]\n",
      "\t\t\t\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\t\t\tdepth: 8\n",
      "\t\t\t\t\t\t\t\tthreshold: 0.7396827475000001\n",
      "\t\t\t\t\t\t\t\tfeature: SeriousDlqin2yrs\n",
      "\t\t\t\t\t\t\t\timpurity: 0.054421768707483054\n",
      "\t\t\t\t\t\t\t\tsamples: [0:6, 1:1]\n",
      "\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\tdepth: 9\n",
      "\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\tsamples: [0:2, 1:1]\n",
      "\t\t\t\t\t\t\t\t\tmessage: Empty split data\n",
      "\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\tdepth: 9\n",
      "\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\tsamples: [0:4]\n",
      "\t\t\t\t\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\tdepth: 4\n",
      "\t\t\t\tthreshold: 9.0\n",
      "\t\t\t\tfeature: MonthlyIncome\n",
      "\t\t\t\timpurity: 0.0035502958579880506\n",
      "\t\t\t\tsamples: [0:12, 1:1]\n",
      "\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\tsamples: [0:2]\n",
      "\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tthreshold: 1.0\n",
      "\t\t\t\t\tfeature: NumberOfTime60-89DaysPastDueNotWorse\n",
      "\t\t\t\t\timpurity: 0.04407713498622602\n",
      "\t\t\t\t\tsamples: [0:10, 1:1]\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\tdepth: 6\n",
      "\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\tsamples: [0:2]\n",
      "\t\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\tdepth: 6\n",
      "\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\tsamples: [0:8, 1:1]\n",
      "\t\t\t\t\t\tmessage: Empty split data\n",
      "\t\t\t\t\t\t------------------------------\n",
      "\t\t\ttype: LEAF\n",
      "\t\t\tdepth: 3\n",
      "\t\t\tclass: 0\n",
      "\t\t\tsamples: [0:15, 1:1]\n",
      "\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_clf_debug.tree, df=df_debug, df_shift=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDecisionTreeClassifier: 2.271366834640503\n",
      "DecisionTreeClassifier: 1.233086109161377\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print('MyDecisionTreeClassifier:', t2 - t1)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print('DecisionTreeClassifier:', t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDecisionTreeClassifier accuracy_score:\n",
      "0.928909952607\n",
      "0.929325683878\n",
      "0.928743660098\n",
      "0.933275130955\n",
      "0.931734087224\n"
     ]
    }
   ],
   "source": [
    "print('MyDecisionTreeClassifier accuracy_score:')\n",
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    # Изначально было y_pred=clf.predict(X_test)\n",
    "    # Но мне кажется, этот вариант не совсем корректный\n",
    "    print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier accuracy_score:\n",
      "0.890537956265\n",
      "0.892658185749\n",
      "0.893780660181\n",
      "0.89307391702\n",
      "0.891655926496\n"
     ]
    }
   ],
   "source": [
    "print('DecisionTreeClassifier accuracy_score:')\n",
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применить для задачи Titanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(df_train.median(axis=0), axis=0)\n",
    "df_train['SexCode'] = df_train['Sex'].map(lambda sex: 1 if sex == 'male' else 0)\n",
    "df_train['AgeGroup'] = df_train['Age']\n",
    "df_train['AgeGroup'] = df_train['AgeGroup'].map(lambda age: int(age // 10) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>SexCode</th>\n",
       "      <th>AgeGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  SexCode  AgeGroup\n",
       "0         0       3  22.0      1      0   7.2500        1         3\n",
       "1         1       1  38.0      1      0  71.2833        0         4\n",
       "2         1       3  26.0      0      0   7.9250        0         3\n",
       "3         1       1  35.0      1      0  53.1000        0         4\n",
       "4         0       3  35.0      0      0   8.0500        1         4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train2 = df_train.drop(([\n",
    "    'PassengerId',\n",
    "    'Name', \n",
    "    'Sex', \n",
    "    'Ticket',\n",
    "    'Cabin',\n",
    "    'Embarked',\n",
    "]), axis=1)\n",
    "\n",
    "df_train2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.      22.       1.     ...,   7.25     1.       3.    ]\n",
      " [  1.      38.       1.     ...,  71.2833   0.       4.    ]\n",
      " [  3.      26.       0.     ...,   7.925    0.       3.    ]\n",
      " ..., \n",
      " [  3.      28.       1.     ...,  23.45     0.       3.    ]\n",
      " [  1.      26.       0.     ...,  30.       1.       3.    ]\n",
      " [  3.      32.       0.     ...,   7.75     1.       4.    ]]\n",
      "[0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0\n",
      " 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0\n",
      " 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "x_train = df_train2.as_matrix(columns=df_train2.columns[1:])\n",
    "y_train = df_train2.as_matrix(columns=df_train2.columns[:1])\n",
    "y_train = y_train.reshape(y_train.shape[0])\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score 0.723880597015\n",
      "best_min_samples_split 1\n",
      "best_max_depth None\n",
      "best_sufficient_share 1.0\n"
     ]
    }
   ],
   "source": [
    "best_score = float('-inf')\n",
    "best_min_samples_split = None\n",
    "best_max_depth = None\n",
    "best_sufficient_share = None\n",
    "for i in range(10):\n",
    "    for j in map(lambda x: x * 2, range(4)):\n",
    "        if j == 0:\n",
    "            j = None\n",
    "        for k in map(lambda x: x / 10, range(4, 12, 2)):\n",
    "            my_clf = MyDecisionTreeClassifier(min_samples_split=i, max_depth=j, sufficient_share=k)\n",
    "            my_clf.fit(x_train2, y_train2)\n",
    "            a_s = accuracy_score(y_pred=my_clf.predict(x_test2), y_true=y_test2)\n",
    "            if a_s > best_score:\n",
    "                best_score = a_s\n",
    "                best_min_samples_split = i\n",
    "                best_max_depth = j\n",
    "                best_sufficient_share = k\n",
    "print('best_score', best_score)\n",
    "print('best_min_samples_split', best_min_samples_split)\n",
    "print('best_max_depth', best_max_depth)\n",
    "print('best_sufficient_share', best_sufficient_share)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, на тренировочной выборке наилучшая прогноза 0.723880597015. Посмотрим, что получится на тестовой выборке kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.fillna(df_test.median(axis=0), axis=0)\n",
    "df_test['SexCode'] = df_test['Sex'].map(lambda sex: 1 if sex == 'male' else 0)\n",
    "df_test['AgeGroup'] = df_test['Age']\n",
    "df_test['AgeGroup'] = df_test['AgeGroup'].map(lambda age: int(age // 10) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>SexCode</th>\n",
       "      <th>AgeGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  SexCode  AgeGroup\n",
       "0       3  34.5      0      0   7.8292        1         4\n",
       "1       3  47.0      1      0   7.0000        0         5\n",
       "2       2  62.0      0      0   9.6875        1         7\n",
       "3       3  27.0      0      0   8.6625        1         3\n",
       "4       3  22.0      1      1  12.2875        0         3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2 = df_test.drop(([\n",
    "    'PassengerId',\n",
    "    'Name', \n",
    "    'Sex', \n",
    "    'Ticket',\n",
    "    'Cabin',\n",
    "    'Embarked',\n",
    "]), axis=1)\n",
    "df_test2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.      34.5      0.     ...,   7.8292   1.       4.    ]\n",
      " [  3.      47.       1.     ...,   7.       0.       5.    ]\n",
      " [  2.      62.       0.     ...,   9.6875   1.       7.    ]\n",
      " ..., \n",
      " [  3.      38.5      0.     ...,   7.25     1.       4.    ]\n",
      " [  3.      27.       0.     ...,   8.05     1.       3.    ]\n",
      " [  3.      27.       1.     ...,  22.3583   1.       3.    ]]\n"
     ]
    }
   ],
   "source": [
    "x_test = df_test2.as_matrix()\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=1)\n",
    "my_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: NON_LEAF\n",
      "depth: 0\n",
      "threshold: 28.0\n",
      "feature: Age\n",
      "impurity: 4.1241486892218404e-09\n",
      "samples: [0:549, 1:342]\n",
      "------------------------------\n",
      "\ttype: NON_LEAF\n",
      "\tdepth: 1\n",
      "\tthreshold: 4.0\n",
      "\tfeature: AgeGroup\n",
      "\timpurity: 2.328636894421976e-09\n",
      "\tsamples: [1:142, 0:210]\n",
      "\t------------------------------\n",
      "\t\ttype: NON_LEAF\n",
      "\t\tdepth: 2\n",
      "\t\tthreshold: 1.0\n",
      "\t\tfeature: Pclass\n",
      "\t\timpurity: 1.280198933528709e-07\n",
      "\t\tsamples: [0:102, 1:61]\n",
      "\t\t------------------------------\n",
      "\t\t\ttype: NON_LEAF\n",
      "\t\t\tdepth: 3\n",
      "\t\t\tthreshold: 1.0\n",
      "\t\t\tfeature: SibSp\n",
      "\t\t\timpurity: 3.3159643107738557e-07\n",
      "\t\t\tsamples: [1:19, 0:63]\n",
      "\t\t\t------------------------------\n",
      "\t\t\t\ttype: LEAF\n",
      "\t\t\t\tdepth: 4\n",
      "\t\t\t\tclass: 0\n",
      "\t\t\t\tsamples: [0:1]\n",
      "\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t------------------------------\n",
      "\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\tdepth: 4\n",
      "\t\t\t\tthreshold: 54.0\n",
      "\t\t\t\tfeature: Age\n",
      "\t\t\t\timpurity: 2.8017608516561765e-07\n",
      "\t\t\t\tsamples: [1:19, 0:62]\n",
      "\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\tsamples: [1:3, 0:12]\n",
      "\t\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tthreshold: 44.5\n",
      "\t\t\t\t\tfeature: Age\n",
      "\t\t\t\t\timpurity: 0.0\n",
      "\t\t\t\t\tsamples: [0:50, 1:16]\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\tdepth: 6\n",
      "\t\t\t\t\t\tthreshold: 0.0\n",
      "\t\t\t\t\t\tfeature: SexCode\n",
      "\t\t\t\t\t\timpurity: 1.5832304233576178e-05\n",
      "\t\t\t\t\t\tsamples: [0:25, 1:8]\n",
      "\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\tdepth: 7\n",
      "\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\tsamples: [0:20, 1:1]\n",
      "\t\t\t\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\t\tdepth: 7\n",
      "\t\t\t\t\t\t\tthreshold: 1.0\n",
      "\t\t\t\t\t\t\tfeature: Parch\n",
      "\t\t\t\t\t\t\timpurity: 0.0003968253968252289\n",
      "\t\t\t\t\t\t\tsamples: [0:5, 1:7]\n",
      "\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\t\t\tdepth: 8\n",
      "\t\t\t\t\t\t\t\tthreshold: 3.0\n",
      "\t\t\t\t\t\t\t\tfeature: Parch\n",
      "\t\t\t\t\t\t\t\timpurity: 0.0\n",
      "\t\t\t\t\t\t\t\tsamples: [0:2, 1:2]\n",
      "\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\tdepth: 9\n",
      "\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\tsamples: [0:1]\n",
      "\t\t\t\t\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\tdepth: 9\n",
      "\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\tsamples: [0:1, 1:2]\n",
      "\t\t\t\t\t\t\t\t\tmessage: Empty split data\n",
      "\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\t\t\tdepth: 8\n",
      "\t\t\t\t\t\t\t\tthreshold: 0.5\n",
      "\t\t\t\t\t\t\t\tfeature: SibSp\n",
      "\t\t\t\t\t\t\t\timpurity: 0.010416666666666685\n",
      "\t\t\t\t\t\t\t\tsamples: [0:3, 1:5]\n",
      "\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\tdepth: 9\n",
      "\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\tsamples: [0:1, 1:1]\n",
      "\t\t\t\t\t\t\t\t\tmessage: Empty split data\n",
      "\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\t\t\t\tdepth: 9\n",
      "\t\t\t\t\t\t\t\t\tthreshold: 13.9771\n",
      "\t\t\t\t\t\t\t\t\tfeature: Fare\n",
      "\t\t\t\t\t\t\t\t\timpurity: 0.027777777777777762\n",
      "\t\t\t\t\t\t\t\t\tsamples: [1:4, 0:2]\n",
      "\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\t\tdepth: 10\n",
      "\t\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\t\tsamples: [1:1, 0:1]\n",
      "\t\t\t\t\t\t\t\t\t\tmessage: Empty split data\n",
      "\t\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\t\tdepth: 10\n",
      "\t\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\t\tsamples: [0:1, 1:3]\n",
      "\t\t\t\t\t\t\t\t\t\tmessage: Empty split data\n",
      "\t\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\tdepth: 6\n",
      "\t\t\t\t\t\tthreshold: 40.0\n",
      "\t\t\t\t\t\tfeature: Age\n",
      "\t\t\t\t\t\timpurity: 1.5832304233576178e-05\n",
      "\t\t\t\t\t\tsamples: [0:25, 1:8]\n",
      "\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\t\tdepth: 7\n",
      "\t\t\t\t\t\t\tthreshold: 26.0\n",
      "\t\t\t\t\t\t\tfeature: Fare\n",
      "\t\t\t\t\t\t\timpurity: -2.7755575615628914e-17\n",
      "\t\t\t\t\t\t\tsamples: [0:20, 1:5]\n",
      "\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\tdepth: 8\n",
      "\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\tsamples: [0:4]\n",
      "\t\t\t\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\t\t\tdepth: 8\n",
      "\t\t\t\t\t\t\t\tthreshold: 19.85625\n",
      "\t\t\t\t\t\t\t\tfeature: Fare\n",
      "\t\t\t\t\t\t\t\timpurity: 6.669334400430382e-05\n",
      "\t\t\t\t\t\t\t\tsamples: [0:16, 1:5]\n",
      "\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\t\t\t\tdepth: 9\n",
      "\t\t\t\t\t\t\t\t\tthreshold: 2.0\n",
      "\t\t\t\t\t\t\t\t\tfeature: Pclass\n",
      "\t\t\t\t\t\t\t\t\timpurity: 0.125\n",
      "\t\t\t\t\t\t\t\t\tsamples: [0:3, 1:1]\n",
      "\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\t\tdepth: 10\n",
      "\t\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\t\tsamples: [0:1]\n",
      "\t\t\t\t\t\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\t\tdepth: 10\n",
      "\t\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\t\tsamples: [0:2, 1:1]\n",
      "\t\t\t\t\t\t\t\t\t\tmessage: Empty split data\n",
      "\t\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\t\t\t\tdepth: 9\n",
      "\t\t\t\t\t\t\t\t\tthreshold: 41.5\n",
      "\t\t\t\t\t\t\t\t\tfeature: Age\n",
      "\t\t\t\t\t\t\t\t\timpurity: 0.0001330849081715435\n",
      "\t\t\t\t\t\t\t\t\tsamples: [0:13, 1:4]\n",
      "\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\t\tdepth: 10\n",
      "\t\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\t\tsamples: [0:10, 1:3]\n",
      "\t\t\t\t\t\t\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\t\t\t\t\tdepth: 10\n",
      "\t\t\t\t\t\t\t\t\t\tthreshold: 40.75\n",
      "\t\t\t\t\t\t\t\t\t\tfeature: Age\n",
      "\t\t\t\t\t\t\t\t\t\timpurity: 0.125\n",
      "\t\t\t\t\t\t\t\t\t\tsamples: [0:3, 1:1]\n",
      "\t\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\t\t\tdepth: 11\n",
      "\t\t\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\t\t\tsamples: [1:1, 0:1]\n",
      "\t\t\t\t\t\t\t\t\t\t\tmessage: Empty split data\n",
      "\t\t\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\t\t\t\t\tdepth: 11\n",
      "\t\t\t\t\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\t\t\t\t\tsamples: [0:2]\n",
      "\t\t\t\t\t\t\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\tdepth: 7\n",
      "\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\tsamples: [0:5, 1:3]\n",
      "\t\t\t\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\ttype: LEAF\n",
      "\t\t\tdepth: 3\n",
      "\t\t\tclass: 0\n",
      "\t\t\tsamples: [0:39, 1:42]\n",
      "\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t------------------------------\n",
      "\t\ttype: NON_LEAF\n",
      "\t\tdepth: 2\n",
      "\t\tthreshold: 33.0\n",
      "\t\tfeature: Age\n",
      "\t\timpurity: 5.551115123125783e-17\n",
      "\t\tsamples: [1:81, 0:108]\n",
      "\t\t------------------------------\n",
      "\t\t\ttype: NON_LEAF\n",
      "\t\t\tdepth: 3\n",
      "\t\t\tthreshold: 1.5\n",
      "\t\t\tfeature: Parch\n",
      "\t\t\timpurity: 3.6324115725711037e-07\n",
      "\t\t\tsamples: [1:39, 0:49]\n",
      "\t\t\t------------------------------\n",
      "\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\tdepth: 4\n",
      "\t\t\t\tthreshold: 36.0\n",
      "\t\t\t\tfeature: Age\n",
      "\t\t\t\timpurity: 0.0017636684303349859\n",
      "\t\t\t\tsamples: [0:5, 1:4]\n",
      "\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\tsamples: [0:4, 1:1]\n",
      "\t\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\tsamples: [1:3, 0:1]\n",
      "\t\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\ttype: LEAF\n",
      "\t\t\t\tdepth: 4\n",
      "\t\t\t\tclass: 0\n",
      "\t\t\t\tsamples: [1:35, 0:44]\n",
      "\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t------------------------------\n",
      "\t\t\ttype: LEAF\n",
      "\t\t\tdepth: 3\n",
      "\t\t\tclass: 0\n",
      "\t\t\tsamples: [0:59, 1:42]\n",
      "\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t------------------------------\n",
      "\ttype: NON_LEAF\n",
      "\tdepth: 1\n",
      "\tthreshold: 0.0\n",
      "\tfeature: SibSp\n",
      "\timpurity: 2.904936546865855e-08\n",
      "\tsamples: [0:339, 1:200]\n",
      "\t------------------------------\n",
      "\t\ttype: NON_LEAF\n",
      "\t\tdepth: 2\n",
      "\t\tthreshold: 17.25\n",
      "\t\tfeature: Fare\n",
      "\t\timpurity: 4.165127642785649e-08\n",
      "\t\tsamples: [0:97, 1:77]\n",
      "\t\t------------------------------\n",
      "\t\t\ttype: NON_LEAF\n",
      "\t\t\tdepth: 3\n",
      "\t\t\tthreshold: 11.0\n",
      "\t\t\tfeature: Age\n",
      "\t\t\timpurity: 6.328995256210668e-07\n",
      "\t\t\tsamples: [0:68, 1:54]\n",
      "\t\t\t------------------------------\n",
      "\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\tdepth: 4\n",
      "\t\t\t\tthreshold: 24.0\n",
      "\t\t\t\tfeature: Age\n",
      "\t\t\t\timpurity: 1.1055472752263817e-05\n",
      "\t\t\t\tsamples: [1:35, 0:43]\n",
      "\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\tsamples: [1:16, 0:25]\n",
      "\t\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\tsamples: [1:19, 0:18]\n",
      "\t\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\tdepth: 4\n",
      "\t\t\t\tthreshold: 40.63335\n",
      "\t\t\t\tfeature: Fare\n",
      "\t\t\t\timpurity: 3.9886403521843805e-06\n",
      "\t\t\t\tsamples: [0:25, 1:19]\n",
      "\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tthreshold: 1.0\n",
      "\t\t\t\t\tfeature: SibSp\n",
      "\t\t\t\t\timpurity: 0.004081632653061329\n",
      "\t\t\t\t\tsamples: [1:3, 0:4]\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\tdepth: 6\n",
      "\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\tsamples: [0:3]\n",
      "\t\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\t\tdepth: 6\n",
      "\t\t\t\t\t\tthreshold: 2.5\n",
      "\t\t\t\t\t\tfeature: Age\n",
      "\t\t\t\t\t\timpurity: 0.125\n",
      "\t\t\t\t\t\tsamples: [1:3, 0:1]\n",
      "\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\tdepth: 7\n",
      "\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\tsamples: [1:2]\n",
      "\t\t\t\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\t\tdepth: 7\n",
      "\t\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\t\tsamples: [0:1, 1:1]\n",
      "\t\t\t\t\t\t\tmessage: Empty split data\n",
      "\t\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\ttype: NON_LEAF\n",
      "\t\t\t\t\tdepth: 5\n",
      "\t\t\t\t\tthreshold: 0.0\n",
      "\t\t\t\t\tfeature: SexCode\n",
      "\t\t\t\t\timpurity: 1.814807925254458e-05\n",
      "\t\t\t\t\tsamples: [0:21, 1:16]\n",
      "\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\tdepth: 6\n",
      "\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\tsamples: [0:12, 1:8]\n",
      "\t\t\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t\t\t------------------------------\n",
      "\t\t\t\t\t\ttype: LEAF\n",
      "\t\t\t\t\t\tdepth: 6\n",
      "\t\t\t\t\t\tclass: 0\n",
      "\t\t\t\t\t\tsamples: [0:9, 1:8]\n",
      "\t\t\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t\t\t------------------------------\n",
      "\t\t\ttype: NON_LEAF\n",
      "\t\t\tdepth: 3\n",
      "\t\t\tthreshold: 1.0\n",
      "\t\t\tfeature: Parch\n",
      "\t\t\timpurity: 1.9112273138416347e-06\n",
      "\t\t\tsamples: [0:29, 1:23]\n",
      "\t\t\t------------------------------\n",
      "\t\t\t\ttype: LEAF\n",
      "\t\t\t\tdepth: 4\n",
      "\t\t\t\tclass: 0\n",
      "\t\t\t\tsamples: [1:1]\n",
      "\t\t\t\tmessage: Node contains only samples of one class\n",
      "\t\t\t\t------------------------------\n",
      "\t\t\t\ttype: LEAF\n",
      "\t\t\t\tdepth: 4\n",
      "\t\t\t\tclass: 0\n",
      "\t\t\t\tsamples: [0:29, 1:22]\n",
      "\t\t\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t\t\t------------------------------\n",
      "\t\ttype: LEAF\n",
      "\t\tdepth: 2\n",
      "\t\tclass: 0\n",
      "\t\tsamples: [1:123, 0:242]\n",
      "\t\tmessage: After splitting one of the nodes is empty\n",
      "\t\t------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_clf.tree, df=df_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=my_clf.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_submission_tree.csv\n",
    "df_predicted = pd.DataFrame({'PassengerId': df_test['PassengerId'], 'Survived': y_pred})\n",
    "df_predicted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predicted.to_csv('sample_submission_tree.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге лучший результат на kaggle - 'находится в обработке...'. Что хуже логистической регрессии и kNN. Возможно, просто алгоритм не слишком подходит к этой задаче или дерево нуждается в доработке."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
